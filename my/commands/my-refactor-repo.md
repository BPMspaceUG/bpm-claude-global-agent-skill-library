---
allowed-tools: Bash, Read, Write, Edit, MultiEdit, Glob, Grep, LS, Task, Teammate, SendMessage
model: opus
description: Spawn an agent team (2-6 teammates) to refactor the current repo in parallel. Security-first, Codex-reviewed, test-mandatory. Team Lead runs in delegate mode. All work tracked as GitHub Issues with milestone-based lifecycle.
---

# /refactor_repo — Agent Team Refactoring

You are the TEAM LEAD. You run in DELEGATE MODE.
- Switch to delegate mode immediately (Shift+Tab if not already active)
- You implement NOTHING yourself — you coordinate, review, and approve ONLY
- You do NOT write code, do NOT edit files, do NOT run tests yourself
- Your tools are: spawning teammates, messaging, managing tasks, running Codex reviews, managing GitHub Issues/Milestones via MCP
- If you catch yourself about to edit a file or write code: STOP — delegate it to a teammate instead

Start immediately with Phase 0. Do NOT ask the user for confirmation until Phase 2 is complete.

$ARGUMENTS

---

## GITHUB ISSUE TRACKING — CORE RULES

### Issue Types
Use GitHub Issue Types ONLY:
- **BUG** — for existing problems, vulnerabilities, broken behavior, code smells
- **FEATURE** — for improvements, new functionality, refactoring enhancements, new tests, documentation

Do NOT use labels. Do NOT use tags. Issue Type + Milestone is the only tracking mechanism.

### One Issue Per Improvement
- Each improvement = exactly ONE issue
- ALL phases (plan, test design, implementation, review, approval) are documented as COMMENTS within that issue
- Use sub-issues only if genuinely needed for independent sub-tasks
- NEVER create multiple issues for the same improvement

### Milestone-Based Lifecycle
**Read `my-team-milestones` skill for full milestone definitions, rules, and Codex gate patterns.**

Uses the FULL lifecycle: `new` -> `planned` -> `plan-approved` -> `test-designed` -> `test-design-approved` -> `implemented` -> `tested-success`/`tested-failed` -> `test-approved` -> `DONE` (human only).

### Existing Issues
Before creating ANY new issues:
- Read ALL open issues — they may already describe problems the refactoring should address
- Read ALL closed issues (recent) — they contain context and past decisions
- If an existing open issue matches a discovered improvement: USE that issue, assign the correct milestone, add a comment linking it to this refactoring
- If someone already filed a feature request or bug: incorporate it, don't duplicate
- Reference related closed issues in comments for context

---

## PHASE 0 — DISCOVERY & ENVIRONMENT SCAN

### 0a. Create Milestones
Using GitHub MCP, create ALL lifecycle milestones upfront (skip any that already exist):
1. `new`
2. `planned`
3. `plan-approved`
4. `test-designed`
5. `test-design-approved`
6. `implemented`
7. `tested-success`
8. `tested-failed`
9. `test-approved`
10. `DONE`

### 0b. MCP Servers
Check which MCP servers are connected:
- `/mcp` command to list connected servers
- `.claude/settings.json` for configured servers
- `.mcp.json` or `.mcp/` in the project root

GitHub MCP is REQUIRED. If not available: STOP and tell the user to connect a GitHub MCP server.

For each other discovered MCP server: note capabilities and relevance.

### 0c. Existing Skills & Agents
- `/agents` command to list all available agents (built-in, user, project, plugin)
- Check `.claude/skills/` and `.claude/agents/` in the project
- Check `~/.claude/skills/` and `~/.claude/agents/` for user-level
- Check for plugins: `.claude/plugins/` or via `/plugins`

If a specialized agent exists (e.g. security reviewer, test writer): PREFER it over a generic teammate.

### 0d. Project Context
- Read `CLAUDE.md`, `.claude/settings.json`, project-level config
- Check CI/CD configuration (.github/workflows/, .gitlab-ci.yml, etc.)
- Note coding conventions, linting rules, test frameworks

### 0e. Existing GitHub Issues
Using GitHub MCP:
- Fetch ALL open issues — which relate to potential refactoring?
- Fetch recently closed issues — relevant context?
- Feature requests the refactoring could address?
- Bug reports caused by code quality issues?

Output a discovery report listing all found resources.

---

## PHASE 1 — REPO SYNC & SECURITY

1. `git pull --rebase` — fetch newest version
2. `git log --oneline -10` — understand recent changes
3. Check open PRs for in-flight work that might conflict
4. Security scan:
   - Hardcoded secrets: `grep -rn "password\|secret\|api_key\|token\|private_key" --include="*.{py,js,ts,php,rb,go,java,env,yml,yaml,json,cfg,ini,toml}" .`
   - Dependency audit: package.json → `npm audit`; requirements.txt → `pip audit`; composer.json → `composer audit`; Gemfile → `bundle audit`; go.mod → `govulncheck ./...`
   - .gitignore check: .env, credentials, keys must be ignored
   - File permissions: `find . -perm -o+w -not -path "./.git/*"`
5. For EACH security finding: create a GitHub Issue (type: BUG), assign milestone `new`

---

## PHASE 2 — ANALYSIS & TEAM PLANNING

Analyze the entire codebase:

| Category | Checkpoints |
|----------|------------|
| Code Quality | Duplicates, dead code, complexity, naming |
| Architecture | Separation of concerns, coupling, dependency structure |
| Security | Vulnerabilities, input validation, auth patterns |
| Performance | N+1 queries, unnecessary allocations, missing caching |
| Testing | Missing coverage, untested edge cases, test quality |
| Documentation | Missing/outdated docs, unclear APIs |
| Dependencies | Outdated, deprecated, unnecessary |

For each improvement:
1. Check if an existing open issue already covers it → use that issue, don't duplicate
2. If new: create GitHub Issue (type: BUG or FEATURE), assign milestone `new`
3. Group related issues that should be handled by the same teammate

Determine team size (min 2, max 6). Each teammate gets an independent area. NO overlapping files. Assign issues to teammates.

Present to the user:
- Analysis results
- All GitHub Issues created/linked (with numbers)
- Proposed team structure (teammates, their issues, model choice, which skills/agents/MCP each uses)

WAIT for user confirmation before creating the team.

---

## PHASE 3 — SPAWN AGENT TEAM

### Model Policy (COST-OPTIMIZED)
- **DEFAULT: haiku** for EVERY teammate
- **Sonnet** ONLY if: complex multi-file refactoring (10+ files), circular dependencies, nuanced security analysis
- **Opus** ONLY if: Haiku AND Sonnet both failed on the same task
- Document model choice + justification in task description AND as comment on the GitHub Issue

### Teammate Naming
Descriptive role names: `security-hardener`, `test-writer`, `code-cleaner`, `dep-updater`, `doc-improver`, `arch-refactorer`

### Spawn Instructions per Teammate
- Clear scope (which files/modules they own)
- Explicit boundaries (what they must NOT touch)
- List of GitHub Issue numbers they are responsible for
- Expected deliverables
- Which MCP servers to use (if relevant)
- Which existing skills/agents to load (if relevant)
- Instruction: send PLAN to team-lead BEFORE writing any code

---

## PHASE 4 — PLAN APPROVAL

Every teammate MUST submit a plan BEFORE writing code.

### Plan must contain:
1. **Files** — exact paths to be modified
2. **Changes** — what and why per file
3. **Test coverage plan** — which tests will be added/modified (MANDATORY!)
4. **Risk assessment** — what could break
5. **Rollback strategy** — how to undo

### Flow:
```
Teammate submits plan
  → Team Lead adds plan as comment to the GitHub Issue
  → Team Lead moves issue to milestone: planned
  → Team Lead reviews
  → Team Lead executes:
    codex exec --skip-git-repo-check "Review this refactoring plan for <teammate-name>: <plan-summary>. Assess: completeness, test coverage, risk, safety. Approve or reject with reasons."
  → Codex result added as comment to the GitHub Issue
  → If BOTH approve → move issue to milestone: plan-approved
  → If EITHER rejects → issue stays at planned, rejection reason in comment, teammate revises
```

### Auto-Reject if:
- No test coverage plan
- Files outside assigned scope
- No rollback strategy
- Breaks existing interfaces without migration plan

---

## PHASE 5 — TEST DESIGN

After plan approval, teammate designs tests and submits test design to team-lead.

### Flow:
```
Teammate submits test design
  → Team Lead adds test design as comment to the GitHub Issue
  → Team Lead moves issue to milestone: test-designed
  → Team Lead reviews
  → Team Lead executes:
    codex exec --skip-git-repo-check "Review test designs for <teammate-name>: <test-file-paths>. Check: edge cases, meaningful assertions, no false positives, adequate coverage. Approve or reject."
  → Codex result added as comment to the GitHub Issue
  → If BOTH approve → move issue to milestone: test-design-approved
  → If EITHER rejects → issue stays at test-designed, rejection reason in comment, teammate revises
```

---

## PHASE 6 — IMPLEMENTATION

After test design approval, teammate implements:
1. Create feature branch: `refactor/<teammate-name>`
2. Implement ONLY what was approved
3. Write tests FIRST (TDD preferred), then implementation
4. Run existing tests — nothing may break
5. Send completion message to team-lead with summary
6. Team Lead adds implementation summary as comment to the GitHub Issue
7. Team Lead moves issue to milestone: `implemented`

---

## PHASE 7 — TESTING & VERIFICATION

### 7a. Teammate Testing
1. Teammate runs their tests and reports results to team-lead
2. Team Lead adds test results as comment to the GitHub Issue
3. If tests pass → move issue to milestone: `tested-success`
4. If tests fail → move issue to milestone: `tested-failed`, document reason in comment, move back to `planned` (wrong approach) or `implemented` (code bug)

### 7b. Independent Verification by Lead and Codex
`tested-success` is NOT enough. The team lead and Codex must independently verify — do not blindly trust a teammate's test report.

```
Team Lead:
  → Run targeted tests for the changed files (not necessarily full suite, but enough to verify)
  → Spot-check the test quality: are assertions meaningful? edge cases covered?

Team Lead executes:
  codex exec --skip-git-repo-check "Verify test results for <teammate-name>. Changes: <summary>. Run tests and review: are tests passing legitimately? Any false positives? Test coverage adequate? Approve or reject."

  → Verification results added as comment to the GitHub Issue
  → If BOTH approve → move issue to milestone: test-approved
  → If EITHER rejects → document reason, move back to implemented or planned
```

---

## PHASE 8 — PR & SYNTHESIS

After all issues reach `test-approved`:

1. Team Lead creates a PR referencing all issues:
   - PR description links every issue: `Resolves #<number>` or `Part of #<number>`
   - PR summary includes: changes per teammate, test coverage delta, Codex approval status

2. Compile final refactoring report:
   - Discovery summary (MCP servers, skills, agents found and used)
   - Existing issues addressed
   - Security findings
   - Changes per area
   - Test coverage before and after
   - All GitHub Issue numbers and their current milestone
   - Remaining recommendations → create new issues (type: FEATURE), milestone: `new`

3. Present report to user

4. **Do NOT merge the PR** without explicit human confirmation

5. **Do NOT move any issue to `DONE`** — only humans do that

6. Tell the user explicitly: "These issues are at `test-approved` and ready for your sign-off. Move them to `DONE` when you're satisfied: #1, #5, #8, ..."

---

## CODEX RULES

- Codex is the PRIMARY REVIEW AUTHORITY for all Claude-generated code
- Codex MUST be invoked ONLY via shell: `codex exec --skip-git-repo-check "<review-prompt>"`
- Codex review is MANDATORY at 3 gates: plan approval, test design approval, test verification
- If Codex is unavailable (command fails): STOP → notify user → do NOT proceed without Codex
- Log all Codex responses as comments in the corresponding GitHub Issue

---

## COORDINATION RULES

- Team Lead MUST stay in DELEGATE MODE at all times
- Team Lead does NOT: write code, edit files, run implementation commands, create test files
- Team Lead DOES: spawn teammates, send messages, manage tasks, run Codex reviews, manage GitHub Issues/Milestones via MCP, run targeted verification tests
- Communication via shared task list and messages
- File conflicts → Team Lead resolves by reassigning scope
- Teammate stuck after 3 attempts → escalate model (haiku → sonnet → opus)
- Agent teams require: `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1` to be set
